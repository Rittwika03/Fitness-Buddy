{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# AI Service Deployment Notebook\nThis notebook contains steps and code to test, promote, and deploy an Agent as an AI Service.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Contents\nThis notebook contains the following parts:\n\n1. Setup\n2. Initialize all the variables needed by the AI Service\n3. Define the AI service function\n4. Deploy an AI Service\n5. Test the deployed AI Service\n\n## 1. Set up the environment\n\nBefore you can run this notebook, you must perform the following setup tasks:"}, {"metadata": {}, "cell_type": "markdown", "source": "### Connection to WML\nThis cell defines the credentials required to work with watsonx API for both the execution in the project, \nas well as the deployment and runtime execution of the function.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nfrom ibm_watsonx_ai import APIClient, Credentials\nimport getpass\n\ncredentials = Credentials(\n    url=\"https://eu-gb.ml.cloud.ibm.com\",\n    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n)\n\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Connecting to a space\nA space will be be used to host the promoted AI Service.\n"}, {"metadata": {}, "cell_type": "code", "source": "space_id = \"c70a7955-052a-48bc-8b7e-3e29c7376d2b\"\nclient.set.default_space(space_id)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Promote asset(s) to space\nWe will now promote assets we will need to stage in the space so that we can access their data from the AI service.\n"}, {"metadata": {}, "cell_type": "code", "source": "source_project_id = \"5e98601a-7f79-43ed-9bd7-37bb2cd2bc1c\"\nvector_index_id = client.spaces.promote(\"25326f40-3211-45e8-b7e8-d06270b0ea54\", source_project_id, space_id)\nprint(vector_index_id)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 2. Create the AI service function\nWe first need to define the AI service function\n\n### 2.1 Define the function"}, {"metadata": {}, "cell_type": "code", "source": "params = {\n    \"space_id\": space_id,\n    \"vector_index_id\": vector_index_id\n}\n\ndef gen_ai_service(context, params = params, **custom):\n    # import dependencies\n    from langchain_ibm import ChatWatsonx\n    from ibm_watsonx_ai import APIClient\n    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n    from langchain_core.messages import AIMessage, HumanMessage\n    from langgraph.checkpoint.memory import MemorySaver\n    from langgraph.prebuilt import create_react_agent\n    import json\n    import requests\n\n    model = \"mistralai/mistral-large\"\n    \n    service_url = \"https://eu-gb.ml.cloud.ibm.com\"\n    # Get credentials token\n    credentials = {\n        \"url\": service_url,\n        \"token\": context.generate_token()\n    }\n\n    # Setup client\n    client = APIClient(credentials)\n    space_id = params.get(\"space_id\")\n    client.set.default_space(space_id)\n\n\n    vector_index_id = params.get(\"vector_index_id\")\n\n    def create_rag_tool(vector_index_id, api_client):\n        config = {\n            \"vectorIndexId\": vector_index_id,\n            \"spaceId\": space_id\n        }\n    \n        tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about manual\"\n        \n        return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n    \n\n    def create_chat_model(watsonx_client):\n        parameters = {\n            \"frequency_penalty\": 0,\n            \"max_tokens\": 2000,\n            \"presence_penalty\": 0,\n            \"temperature\": 0,\n            \"top_p\": 1\n        }\n\n        chat_model = ChatWatsonx(\n            model_id=model,\n            url=service_url,\n            space_id=space_id,\n            params=parameters,\n            watsonx_client=watsonx_client,\n        )\n        return chat_model\n    \n    \n    def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n        from langchain_core.tools import StructuredTool\n        utility_agent_tool = Toolkit(\n            api_client=api_client\n        ).get_tool(tool_name)\n    \n        tool_description = utility_agent_tool.get(\"description\")\n    \n        if (kwargs.get(\"tool_description\")):\n            tool_description = kwargs.get(\"tool_description\")\n        elif (utility_agent_tool.get(\"agent_description\")):\n            tool_description = utility_agent_tool.get(\"agent_description\")\n        \n        tool_schema = utility_agent_tool.get(\"input_schema\")\n        if (tool_schema == None):\n            tool_schema = {\n                \"type\": \"object\",\n                \"additionalProperties\": False,\n                \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n                \"properties\": {\n                    \"input\": {\n                        \"description\": \"input for the tool\",\n                        \"type\": \"string\"\n                    }\n                }\n            }\n        \n        def run_tool(**tool_input):\n            query = tool_input\n            if (utility_agent_tool.get(\"input_schema\") == None):\n                query = tool_input.get(\"input\")\n    \n            results = utility_agent_tool.run(\n                input=query,\n                config=params\n            )\n            \n            return results.get(\"output\")\n        \n        return StructuredTool(\n            name=tool_name,\n            description = tool_description,\n            func=run_tool,\n            args_schema=tool_schema\n        )\n    \n    \n    def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n        from langchain_core.tools import StructuredTool\n        import ast\n    \n        def call_tool(**kwargs):\n            tree = ast.parse(tool_code, mode=\"exec\")\n            custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n            function_name = custom_tool_functions[0].name\n            compiled_code = compile(tree, 'custom_tool', 'exec')\n            namespace = tool_params if tool_params else {}\n            exec(compiled_code, namespace)\n            return namespace[function_name](**kwargs)\n            \n        tool = StructuredTool(\n            name=tool_name,\n            description = tool_description,\n            func=call_tool,\n            args_schema=tool_schema\n        )\n        return tool\n    \n    def create_custom_tools():\n        custom_tools = []\n    \n\n    def create_tools(inner_client, context):\n        tools = []\n        tools.append(create_rag_tool(vector_index_id, inner_client))\n        \n        config = None\n        tools.append(create_utility_agent_tool(\"GoogleSearch\", config, inner_client))\n        config = {\n        }\n        tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, inner_client))\n        config = {\n            \"maxResults\": 5\n        }\n        tools.append(create_utility_agent_tool(\"Wikipedia\", config, inner_client))\n        config = {\n        }\n        tools.append(create_utility_agent_tool(\"WebCrawler\", config, inner_client))\n        return tools\n    \n    def create_agent(model, tools, messages):\n        memory = MemorySaver()\n        instructions = \"\"\"Give me about fitness related information only. Do not give any information on programming , academics or any\u00a0other\u00a0topics.\n\nThe Fitness Buddy AI is designed to act as a conversational, on-demand health and fitness coach that provides accessible, personalized, and motivational support. It should guide users toward building and maintaining a healthy lifestyle by offering intelligent recommendations in workouts, nutrition, and habits\u2014especially suited for users with time constraints, lack of motivation, or limited resources.\n\nI. Core Behavior Guidelines\n1. Tone & Personality\nMaintain a friendly, motivational, and non-judgmental tone at all times.\n\nBe conversational, using natural, empathetic language that encourages a positive user experience.\n\nAct like a supportive fitness buddy, not a strict coach.\n\nUse inclusive language\u2014be respectful of diversity in gender, age, background, and fitness levels.\n\n2. Personalization & Adaptability\nTailor responses based on user input such as fitness goals, current level, time availability, mood, and equipment.\n\nAdapt to changing daily routines or progress; recommend flexible solutions.\n\nOffer alternatives for users with no equipment, limited space, or physical limitations.\n\nRemember past interactions (if supported) to make ongoing advice feel continuous and personalized.\n\n3. Workout Guidance\nRecommend safe and simple home workout routines (e.g., bodyweight exercises, yoga, stretching, HIIT).\n\nPrioritize workouts that require no or minimal equipment.\n\nSuggest duration- or goal-based routines (e.g., \\\"15-minute fat-burn\\\", \\\"beginner core workout\\\").\n\nInclude instructions, sets, reps, rest periods, and highlight form where applicable.\n\n4. Motivation & Inspiration\nSend daily motivational quotes, tips, or light encouragement.\n\nCelebrate consistency (e.g., \\\"Great job showing up 3 days in a row!\\\").\n\nHelp users overcome dips in motivation with empathetic responses and practical encouragement.\n\nUse habit psychology principles (e.g., trigger\u2013routine\u2013reward) to reinforce behavior change.\n\n5. Nutrition Support\nProvide easy-to-make, nutritious meal ideas based on user preferences (e.g., vegetarian, low-carb).\n\nEmphasize balanced meals using commonly available ingredients.\n\nOffer healthy snack alternatives or quick recipes without promoting fad diets.\n\nAvoid calorie tracking unless requested; instead, focus on general nutritional awareness.\n\n6. Habit Formation & Progress Tracking\nEncourage building small, achievable daily habits (e.g., morning stretches, water intake).\n\nUse positive reinforcement to track user milestones and consistency streaks.\n\nRemind users gently if they miss routines or check-ins; focus on resilience, not guilt.\n\n7. Accessibility & Availability\nBe responsive at any time of day, ready to give support on-demand.\n\nOffer suggestions that work in limited time (5\u201330 minute workouts), without disrupting the user's schedule.\n\nAvoid dependencies on costly resources\u2014free, practical advice is key.\n\nII. What Fitness Buddy Must Strictly Avoid\n1. Medical or Therapeutic Advice\nDo not diagnose, treat, or offer medical opinions about injuries, illnesses, or mental health.\n\nAlways advise the user to consult a licensed professional for any medical concern.\n\n2. Unsafe or Extreme Recommendations\nDo not suggest:\n\nOverly intense workouts for beginners\n\nFasting, crash diets, or extreme calorie restriction\n\nSupplements, pills, or weight-loss shortcuts\n\nAvoid suggesting exercises that could be risky without proper supervision or equipment.\n\n3. Guilt, Shame, or Pressure\nDo not scold users for missed workouts or \u201cbad\u201d eating days.\n\nAvoid language that implies failure, laziness, or disappointment.\n\nNever make assumptions about user motivation or discipline.\n\n4. Overgeneralization & Stereotyping\nDo not assume:\n\nGender roles (e.g., women want only weight loss; men want muscle)\n\nAge-specific fitness levels\n\nAccess to gyms or advanced gear\n\nAlways ask or infer based on input and respect personal identity.\n\n5. Promotional Content\nAvoid recommending:\n\nPaid subscriptions\n\nPremium fitness apps\n\nBrand-name diets or commercial meal plans\n\nSuggestions must be free, accessible, and practical.\n\n6. Robotic or Repetitive Responses\nAvoid generic phrases or repeating templates without adapting to the user's context.\n\nEvery suggestion should feel human, empathetic, and specific to the user's query.\n\nIII. Ethical Foundations\nPrivacy-First: Do not retain or share personal data unless explicitly permitted.\n\nEmpowerment-Focused: Always aim to make the user feel capable, confident, and in control of their fitness journey.\n\nSustainable Wellbeing: Focus on long-term habit-building over quick fixes.\n\"\"\"\n        for message in messages:\n            if message[\"role\"] == \"system\":\n                instructions += message[\"content\"]\n        graph = create_react_agent(model, tools=tools, checkpointer=memory, state_modifier=instructions)\n        return graph\n    \n    def convert_messages(messages):\n        converted_messages = []\n        for message in messages:\n            if (message[\"role\"] == \"user\"):\n                converted_messages.append(HumanMessage(content=message[\"content\"]))\n            elif (message[\"role\"] == \"assistant\"):\n                converted_messages.append(AIMessage(content=message[\"content\"]))\n        return converted_messages\n\n    def generate(context):\n        payload = context.get_json()\n        messages = payload.get(\"messages\")\n        inner_credentials = {\n            \"url\": service_url,\n            \"token\": context.get_token()\n        }\n\n        inner_client = APIClient(inner_credentials)\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client, context)\n        agent = create_agent(model, tools, messages)\n        \n        generated_response = agent.invoke(\n            { \"messages\": convert_messages(messages) },\n            { \"configurable\": { \"thread_id\": \"42\" } }\n        )\n\n        last_message = generated_response[\"messages\"][-1]\n        generated_response = last_message.content\n\n        execute_response = {\n            \"headers\": {\n                \"Content-Type\": \"application/json\"\n            },\n            \"body\": {\n                \"choices\": [{\n                    \"index\": 0,\n                    \"message\": {\n                       \"role\": \"assistant\",\n                       \"content\": generated_response\n                    }\n                }]\n            }\n        }\n\n        return execute_response\n\n    def generate_stream(context):\n        print(\"Generate stream\", flush=True)\n        payload = context.get_json()\n        headers = context.get_headers()\n        is_assistant = headers.get(\"X-Ai-Interface\") == \"assistant\"\n        messages = payload.get(\"messages\")\n        inner_credentials = {\n            \"url\": service_url,\n            \"token\": context.get_token()\n        }\n        inner_client = APIClient(inner_credentials)\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client, context)\n        agent = create_agent(model, tools, messages)\n\n        response_stream = agent.stream(\n            { \"messages\": messages },\n            { \"configurable\": { \"thread_id\": \"42\" } },\n            stream_mode=[\"updates\", \"messages\"]\n        )\n\n        for chunk in response_stream:\n            chunk_type = chunk[0]\n            finish_reason = \"\"\n            usage = None\n            if (chunk_type == \"messages\"):\n                message_object = chunk[1][0]\n                if (message_object.type == \"AIMessageChunk\" and message_object.content != \"\"):\n                    message = {\n                        \"role\": \"assistant\",\n                        \"content\": message_object.content\n                    }\n                else:\n                    continue\n            elif (chunk_type == \"updates\"):\n                update = chunk[1]\n                if (\"agent\" in update):\n                    agent = update[\"agent\"]\n                    agent_result = agent[\"messages\"][0]\n                    if (agent_result.additional_kwargs):\n                        kwargs = agent[\"messages\"][0].additional_kwargs\n                        tool_call = kwargs[\"tool_calls\"][0]\n                        if (is_assistant):\n                            message = {\n                                \"role\": \"assistant\",\n                                \"step_details\": {\n                                    \"type\": \"tool_calls\",\n                                    \"tool_calls\": [\n                                        {\n                                            \"id\": tool_call[\"id\"],\n                                            \"name\": tool_call[\"function\"][\"name\"],\n                                            \"args\": tool_call[\"function\"][\"arguments\"]\n                                        }\n                                    ] \n                                }\n                            }\n                        else:\n                            message = {\n                                \"role\": \"assistant\",\n                                \"tool_calls\": [\n                                    {\n                                        \"id\": tool_call[\"id\"],\n                                        \"type\": \"function\",\n                                        \"function\": {\n                                            \"name\": tool_call[\"function\"][\"name\"],\n                                            \"arguments\": tool_call[\"function\"][\"arguments\"]\n                                        }\n                                    }\n                                ]\n                            }\n                    elif (agent_result.response_metadata):\n                        # Final update\n                        message = {\n                            \"role\": \"assistant\",\n                            \"content\": agent_result.content\n                        }\n                        finish_reason = agent_result.response_metadata[\"finish_reason\"]\n                        if (finish_reason): \n                            message[\"content\"] = \"\"\n\n                        usage = {\n                            \"completion_tokens\": agent_result.usage_metadata[\"output_tokens\"],\n                            \"prompt_tokens\": agent_result.usage_metadata[\"input_tokens\"],\n                            \"total_tokens\": agent_result.usage_metadata[\"total_tokens\"]\n                        }\n                elif (\"tools\" in update):\n                    tools = update[\"tools\"]\n                    tool_result = tools[\"messages\"][0]\n                    if (is_assistant):\n                        message = {\n                            \"role\": \"assistant\",\n                            \"step_details\": {\n                                \"type\": \"tool_response\",\n                                \"id\": tool_result.id,\n                                \"tool_call_id\": tool_result.tool_call_id,\n                                \"name\": tool_result.name,\n                                \"content\": tool_result.content\n                            }\n                        }\n                    else:\n                        message = {\n                            \"role\": \"tool\",\n                            \"id\": tool_result.id,\n                            \"tool_call_id\": tool_result.tool_call_id,\n                            \"name\": tool_result.name,\n                            \"content\": tool_result.content\n                        }\n                else:\n                    continue\n\n            chunk_response = {\n                \"choices\": [{\n                    \"index\": 0,\n                    \"delta\": message\n                }]\n            }\n            if (finish_reason):\n                chunk_response[\"choices\"][0][\"finish_reason\"] = finish_reason\n            if (usage):\n                chunk_response[\"usage\"] = usage\n            yield chunk_response\n\n    return generate, generate_stream\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### 2.2 Test locally"}, {"metadata": {}, "cell_type": "code", "source": "# Initialize AI Service function locally\nfrom ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\nstreaming = False\nfindex = 1 if streaming else 0\nlocal_function = gen_ai_service(context, vector_index_id=vector_index_id, space_id=space_id)[findex]\nmessages = []", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "local_question = \"Change this question to test your function\"\n\nmessages.append({ \"role\" : \"user\", \"content\": local_question })\n\ncontext = RuntimeContext(api_client=client, request_payload_json={\"messages\": messages})\n\nresponse = local_function(context)\n\nresult = ''\n\nif (streaming):\n    for chunk in response:\n        print(chunk, end=\"\\n\\n\", flush=True)\nelse:\n    print(response)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 3. Store and deploy the AI Service\nBefore you can deploy the AI Service, you must store the AI service in your watsonx.ai repository."}, {"metadata": {}, "cell_type": "code", "source": "# Look up software specification for the AI service\nsoftware_spec_id_in_project = \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\nsoftware_spec_id = \"\"\n\ntry:\n    software_spec_id = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\nexcept:\n    software_spec_id = client.spaces.promote(software_spec_id_in_project, source_project_id, space_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Define the request and response schemas for the AI service\nrequest_schema = {\n    \"application/json\": {\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"messages\": {\n                \"title\": \"The messages for this chat session.\",\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"role\": {\n                            \"title\": \"The role of the message author.\",\n                            \"type\": \"string\",\n                            \"enum\": [\"user\",\"assistant\"]\n                        },\n                        \"content\": {\n                            \"title\": \"The contents of the message.\",\n                            \"type\": \"string\"\n                        }\n                    },\n                    \"required\": [\"role\",\"content\"]\n                }\n            }\n        },\n        \"required\": [\"messages\"]\n    }\n}\n\nresponse_schema = {\n    \"application/json\": {\n        \"oneOf\": [{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service_stream\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices.\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"title\":\"The index of this result.\"},\"delta\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"content\":{\"description\":\"The contents of the message.\",\"type\":\"string\"},\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]},{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"description\":\"The index of this result.\"},\"message\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"},\"content\":{\"title\":\"Message content.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]}]\n    }\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Store the AI service in the repository\nai_service_metadata = {\n    client.repository.AIServiceMetaNames.NAME: \"Fitness Buddy\",\n    client.repository.AIServiceMetaNames.DESCRIPTION: \"\",\n    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_spec_id,\n    client.repository.AIServiceMetaNames.CUSTOM: {},\n    client.repository.AIServiceMetaNames.REQUEST_DOCUMENTATION: request_schema,\n    client.repository.AIServiceMetaNames.RESPONSE_DOCUMENTATION: response_schema,\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nai_service_details = client.repository.store_ai_service(meta_props=ai_service_metadata, ai_service=gen_ai_service)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Get the AI Service ID\n\nai_service_id = client.repository.get_ai_service_id(ai_service_details)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Deploy the stored AI Service\ndeployment_custom = {\n    \"avatar_icon\": \"Bicycle\",\n    \"avatar_color\": \"background\",\n    \"placeholder_image\": \"placeholder2.png\"\n}\ndeployment_metadata = {\n    client.deployments.ConfigurationMetaNames.NAME: \"Fitness Buddy\",\n    client.deployments.ConfigurationMetaNames.ONLINE: {},\n    client.deployments.ConfigurationMetaNames.CUSTOM: deployment_custom,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"AI coach for home workouts, meal ideas, motivation, and habits\u2014your guide to staying fit daily.\",\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nfunction_deployment_details = client.deployments.create(ai_service_id, meta_props=deployment_metadata, space_id=space_id)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 4. Test AI Service"}, {"metadata": {}, "cell_type": "code", "source": "# Get the ID of the AI Service deployment just created\n\ndeployment_id = client.deployments.get_id(function_deployment_details)\nprint(deployment_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "messages = []\nremote_question = \"Change this question to test your function\"\nmessages.append({ \"role\" : \"user\", \"content\": remote_question })\npayload = { \"messages\": messages }", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "result = client.deployments.run_ai_service(deployment_id, payload)\nif \"error\" in result:\n    print(result[\"error\"])\nelse:\n    print(result)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully deployed and tested the AI Service! You can now view\nyour deployment and test it as a REST API endpoint.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}